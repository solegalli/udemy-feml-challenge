{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment:\n",
    "\n",
    "Beat the performance of my Lasso regression by **using different feature engineering steps ONLY!!**.\n",
    "\n",
    "The performance of my current model, as shown in this notebook is:\n",
    "\n",
    "- test mse: 1063016789.3316755\n",
    "- test rmse: 32603.938248801718\n",
    "- test r2: 0.8453144708738004\n",
    "\n",
    "To beat my model you will need a test r2 bigger than 0.85 and a rmse smaller than 32603.\n",
    "\n",
    "\n",
    "=====================================================================================================\n",
    "\n",
    "\n",
    "### Conditions:\n",
    "\n",
    "- You MUST NOT change the hyperparameters of the Lasso.\n",
    "- You MUST use the same seeds in Lasso and train_test_split as I show in this notebook (random_state)\n",
    "- You MUST use all the features of the dataset (except Id) - you MUST NOT select features\n",
    "\n",
    "\n",
    "=====================================================================================================\n",
    "\n",
    "\n",
    "### If you beat my model:\n",
    "\n",
    "Make a pull request with your notebook to this github repo:\n",
    "https://github.com/solegalli/udemy-feml-challenge\n",
    "\n",
    "And add your notebook to the folder:\n",
    "\n",
    "-StudentsSolutions_v1.0.0\n",
    "\n",
    "### How to make the PR\n",
    "\n",
    "1) fork the repo:\n",
    "\n",
    "Go to https://github.com/solegalli/udemy-feml-challenge, and click on the **fork** button at the top-right\n",
    "\n",
    "2) clone your forked repo into your local computer:\n",
    "\n",
    "- Go to www.github.com/yourusername/udemy-feml-challenge\n",
    "- Click the green button that says clone or download\n",
    "- copy the url that opens up\n",
    "- power up a git console\n",
    "- type: git clone (paste the url you copied from github)\n",
    "- done\n",
    "\n",
    "3) Make a copy of the jupyter notebook and add your name:\n",
    "\n",
    "- Open up the Jupyter notebook called 13-Assignement.ipynb\n",
    "- Click the \"File\" button at the top-right and then click \"Make a copy\"\n",
    "- **Work your solution in the Copy** and not in the original assignment (otherwise there will be conflicts when making the PR)\n",
    "- Change the name of the copy of the notebook to: 13-Assignement_yourname.ipynb\n",
    "- Move the notebook to the folder **StudentsSolutions_v1.0.0**\n",
    "- done\n",
    "\n",
    "When you finish, just commit the new notebook to your fork and then make a PR to my repo.\n",
    "\n",
    "- git add StudentsSolutions_v1.0.0/13-Assignement_yourname.ipynb\n",
    "- git commit -m \"your commit message\"\n",
    "- git push origin master or git push origin yourfeaturebranch\n",
    "- go to your repo and make a pull request.\n",
    "\n",
    "\n",
    "## But i have a notebook ready and I haven't cloned the repo yet, how can I make the PR?\n",
    "\n",
    "If you worked in the copy you downloaded from Udemy before forking and cloning this repo, then follow this steps:\n",
    "\n",
    "1) fork the repo:\n",
    "\n",
    "Go to https://github.com/solegalli/udemy-feml-challenge, and click on the fork button at the top-right\n",
    "\n",
    "2) clone your forked repo into your local computer:\n",
    "\n",
    "Go to www.github.com/yourusername/udemy-feml-challenge\n",
    "\n",
    "- Click the green button that says clone or download\n",
    "- Copy the url that opens up\n",
    "- Power up a git console\n",
    "- Type: git clone (paste the url you copied from github)\n",
    "- Done\n",
    "\n",
    "3) Rename your solution as follows and copy it into your cloned repo:\n",
    "\n",
    "- Rename your solution notebook to: 13-Assignement_yourname.ipynb\n",
    "- Copy this file into the cloned repo, inside the folder **StudentsSolutions_v1.0.0**\n",
    "- Done\n",
    "\n",
    "When you finish, just commit the new notebook to your fork and then make a PR to my repo\n",
    "\n",
    "- git add StudentsSolutions_v1.0.0/13-Assignement_yourname.ipynb\n",
    "- git commit -m \"your commit message\"\n",
    "- git push origin master or git push origin yourfeaturebranch\n",
    "- go to your repo and make a pull request.\n",
    "\n",
    "**Good luck!!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Prices dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for the model\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# for feature engineering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from feature_engine import imputation as mdi\n",
    "from feature_engine import discretisation as dsc\n",
    "from feature_engine import encoding as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "data = pd.read_csv('../houseprice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 18 continuous variables\n",
      "There are 14 discrete variables\n",
      "There are 4 temporal variables\n",
      "There are 43 categorical variables\n"
     ]
    }
   ],
   "source": [
    "# make lists of variable types\n",
    "\n",
    "categorical = [var for var in data.columns if data[var].dtype == 'O']\n",
    "\n",
    "year_vars = [var for var in data.columns if 'Yr' in var or 'Year' in var]\n",
    "\n",
    "discrete = [\n",
    "    var for var in data.columns if data[var].dtype != 'O'\n",
    "    and len(data[var].unique()) < 20 and var not in year_vars\n",
    "]\n",
    "\n",
    "numerical = [\n",
    "    var for var in data.columns if data[var].dtype != 'O'\n",
    "    if var not in discrete and var not in ['Id', 'SalePrice']\n",
    "    and var not in year_vars\n",
    "]\n",
    "\n",
    "print('There are {} continuous variables'.format(len(numerical)))\n",
    "print('There are {} discrete variables'.format(len(discrete)))\n",
    "print('There are {} temporal variables'.format(len(year_vars)))\n",
    "print('There are {} categorical variables'.format(len(categorical)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: keep the random_state to zero for reproducibility\n",
    "# Let's separate into train and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(\n",
    "    ['Id', 'SalePrice'], axis=1),\n",
    "    data['SalePrice'],\n",
    "    test_size=0.1,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate elapsed time\n",
    "\n",
    "def elapsed_years(df, var):\n",
    "    # capture difference between year variable and\n",
    "    # year the house was sold\n",
    "    \n",
    "    df[var] = df['YrSold'] - df[var]\n",
    "    return df\n",
    "\n",
    "for var in ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt']:\n",
    "    X_train = elapsed_years(X_train, var)\n",
    "    X_test = elapsed_years(X_test, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop YrSold\n",
    "X_train.drop('YrSold', axis=1, inplace=True)\n",
    "X_test.drop('YrSold', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the column names for use later in the notebook\n",
    "final_columns = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will treat discrete variables as if they were categorical\n",
    "# to treat discrete as categorical using Feature-engine\n",
    "# we need to re-cast them as object\n",
    "\n",
    "X_train[discrete] = X_train[discrete].astype('O')\n",
    "X_test[discrete] = X_test[discrete].astype('O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_pipe = Pipeline([\n",
    "\n",
    "    # missing data imputation - section 4\n",
    "    ('missing_ind',\n",
    "     mdi.AddMissingIndicator(\n",
    "         variables=['LotFrontage', 'MasVnrArea', 'GarageYrBlt'])),\n",
    "\n",
    "    ('imputer_num',\n",
    "     mdi.MeanMedianImputer(\n",
    "         imputation_method='median',\n",
    "         variables=['LotFrontage', 'MasVnrArea', 'GarageYrBlt'])),\n",
    "\n",
    "    ('imputer_cat', mdi.CategoricalImputer(variables=categorical)),\n",
    "\n",
    "\n",
    "    # categorical encoding - section 6\n",
    "    ('rare_label_enc',\n",
    "     ce.RareLabelEncoder(tol=0.05, n_categories=1, variables=categorical + discrete)),\n",
    "\n",
    "    # newly available categorical encoder, uses trees predictions\n",
    "    ('categorical_enc',\n",
    "     ce.DecisionTreeEncoder(random_state=2909, variables=categorical + discrete)),\n",
    "\n",
    "    # discretisation - section 8\n",
    "    ('discretisation',\n",
    "     dsc.DecisionTreeDiscretiser(random_state=2909, variables=numerical)),\n",
    "\n",
    "    # feature Scaling - section 10\n",
    "    ('scaler', StandardScaler()),\n",
    "\n",
    "    # regression\n",
    "    ('lasso', Lasso(random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Grid ad the cross-validation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create the grid with all the parameters that we would like to test\n",
    "\n",
    "param_grid = {\n",
    "    # try different feature engineering parameters\n",
    "    'rare_label_enc__tol': [0.01, 0.02, 0.03, 0.04, 0.05]\n",
    "}\n",
    "\n",
    "\n",
    "# now we set up the grid search with cross-validation\n",
    "grid_search = GridSearchCV(house_pipe, param_grid,\n",
    "                           cv=5, n_jobs=-1, scoring='r2')\n",
    "\n",
    "# cv=5 is the cross-validation steps\n",
    "# no_jobs =-1 indicates to use all available cpus\n",
    "# scoring='r2' indicates to evaluate the model performance with the r2\n",
    "\n",
    "# for more details in the grid parameters visit:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we train over all the possible combinations of the parameters above\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we print the best score over the train set\n",
    "print((\"best roc-auc from grid search: %3f\"\n",
    "       % grid_search.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can print the best estimator parameters like this\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the predictions\n",
    "X_train_preds = grid_search.predict(X_train)\n",
    "X_test_preds = grid_search.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model performance:\n",
    "\n",
    "print('train mse: {}'.format(mean_squared_error(y_train, X_train_preds, squared=True)))\n",
    "print('train rmse: {}'.format(mean_squared_error(y_train, X_train_preds, squared=False)))\n",
    "print('train r2: {}'.format(r2_score(y_train, X_train_preds)))\n",
    "print()\n",
    "print('test mse: {}'.format(mean_squared_error(y_test, X_test_preds,squared=True)))\n",
    "print('test rmse: {}'.format(mean_squared_error(y_test, X_test_preds, squared=False)))\n",
    "print('test r2: {}'.format(r2_score(y_test, X_test_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predictions vs real value\n",
    "\n",
    "plt.scatter(y_test,X_test_preds)\n",
    "plt.xlabel('True Price')\n",
    "plt.ylabel('Predicted Price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore the importance of the features\n",
    "# the importance is given by the absolute value of the coefficient\n",
    "# assigned by the Lasso\n",
    "\n",
    "importance = pd.Series(np.abs(grid_search.best_estimator_['lasso'].coef_))\n",
    "importance.index = list(final_columns)+['LotFrontage_na', 'MasVnrArea_na',  'GarageYrBlt_na']\n",
    "importance.sort_values(inplace=True, ascending=False)\n",
    "importance.plot.bar(figsize=(18,6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "583px",
    "left": "0px",
    "right": "1324px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
